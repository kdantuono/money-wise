name: Lockfile Integrity Monitoring

on:
  push:
    paths:
      - 'package-lock.json'
      - 'package.json'
      - '.github/workflows/**'
  pull_request:
    paths:
      - 'package-lock.json'
      - 'package.json'
  schedule:
    # Continuous monitoring every 30 minutes during business hours
    - cron: '*/30 8-18 * * 1-5'
    # Daily comprehensive check at 6 AM UTC
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      force_analysis:
        description: 'Force comprehensive analysis'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  issues: write
  pull-requests: write

jobs:
  integrity-monitoring:
    name: Lockfile Integrity Monitoring
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: ðŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: ðŸ” Comprehensive Integrity Analysis
        id: integrity-analysis
        run: |
          echo "ðŸ” Starting comprehensive lockfile integrity analysis..."

          # Initialize analysis results
          echo "integrity_score=100" >> $GITHUB_OUTPUT
          echo "risk_level=low" >> $GITHUB_OUTPUT
          echo "issues_found=false" >> $GITHUB_OUTPUT
          echo "requires_action=false" >> $GITHUB_OUTPUT
          echo "alert_level=none" >> $GITHUB_OUTPUT

          # Analysis results storage
          mkdir -p .github/integrity-reports
          report_file=".github/integrity-reports/$(date -u '+%Y%m%d-%H%M%S')-integrity-report.json"

          # Start comprehensive analysis
          cat > integrity_analysis.js << 'EOF'
          const fs = require('fs');
          const crypto = require('crypto');

          class LockfileIntegrityAnalyzer {
            constructor() {
              this.issues = [];
              this.warnings = [];
              this.score = 100;
              this.riskFactors = [];
            }

            async analyze() {
              console.log('ðŸ” Starting comprehensive integrity analysis...');

              // Check 1: File existence and accessibility
              await this.checkFileExistence();

              // Check 2: JSON structure validation
              await this.validateJsonStructure();

              // Check 3: Dependency consistency validation
              await this.validateDependencyConsistency();

              // Check 4: Version conflict detection
              await this.detectVersionConflicts();

              // Check 5: Security vulnerability scanning
              await this.scanSecurityVulnerabilities();

              // Check 6: Size and growth analysis
              await this.analyzeSizeAndGrowth();

              // Check 7: Package integrity verification
              await this.verifyPackageIntegrity();

              // Check 8: Predictive risk assessment
              await this.assessPredictiveRisk();

              return this.generateReport();
            }

            async checkFileExistence() {
              console.log('ðŸ“ Checking file existence and accessibility...');

              if (!fs.existsSync('package-lock.json')) {
                this.addIssue('critical', 'missing_lockfile', 'package-lock.json is missing');
                this.score -= 50;
                return;
              }

              if (!fs.existsSync('package.json')) {
                this.addIssue('critical', 'missing_package_json', 'package.json is missing');
                this.score -= 50;
                return;
              }

              // Check file permissions and size
              const lockfileStat = fs.statSync('package-lock.json');
              if (lockfileStat.size < 100) {
                this.addIssue('high', 'truncated_lockfile', 'Lockfile appears truncated (< 100 bytes)');
                this.score -= 30;
              } else if (lockfileStat.size > 50 * 1024 * 1024) { // 50MB
                this.addWarning('large_lockfile', 'Lockfile is unusually large (> 50MB)');
                this.score -= 5;
              }
            }

            async validateJsonStructure() {
              console.log('ðŸ“Š Validating JSON structure...');

              try {
                const packageJson = JSON.parse(fs.readFileSync('package.json', 'utf8'));
                const lockfileJson = JSON.parse(fs.readFileSync('package-lock.json', 'utf8'));

                // Validate required fields
                if (!lockfileJson.packages) {
                  this.addIssue('high', 'missing_packages_field', 'Lockfile missing required "packages" field');
                  this.score -= 25;
                }

                if (!lockfileJson.lockfileVersion) {
                  this.addWarning('missing_version', 'Lockfile missing version information');
                  this.score -= 5;
                } else if (lockfileJson.lockfileVersion < 2) {
                  this.addWarning('old_lockfile_version', `Old lockfile version ${lockfileJson.lockfileVersion}`);
                  this.score -= 10;
                }

                // Check name consistency
                if (packageJson.name && lockfileJson.name && packageJson.name !== lockfileJson.name) {
                  this.addIssue('medium', 'name_mismatch', 'Package name mismatch between files');
                  this.score -= 15;
                }

                this.packageJson = packageJson;
                this.lockfileJson = lockfileJson;

              } catch (error) {
                this.addIssue('critical', 'invalid_json', `JSON parsing failed: ${error.message}`);
                this.score -= 40;
              }
            }

            async validateDependencyConsistency() {
              if (!this.packageJson || !this.lockfileJson) return;

              console.log('ðŸ”— Validating dependency consistency...');

              const packageDeps = {
                ...this.packageJson.dependencies || {},
                ...this.packageJson.devDependencies || {}
              };

              const lockfileDeps = this.lockfileJson.packages?.[""]?.dependencies || {};
              const lockfileDevDeps = this.lockfileJson.packages?.[""]?.devDependencies || {};

              // Check for missing dependencies
              for (const [name, version] of Object.entries(packageDeps)) {
                if (!lockfileDeps[name] && !lockfileDevDeps[name]) {
                  this.addIssue('medium', 'missing_dependency', `Dependency ${name} in package.json but not in lockfile`);
                  this.score -= 10;
                }
              }

              // Check for orphaned dependencies
              const allLockfileDeps = { ...lockfileDeps, ...lockfileDevDeps };
              for (const name of Object.keys(allLockfileDeps)) {
                if (!packageDeps[name]) {
                  this.addWarning('orphaned_dependency', `Dependency ${name} in lockfile but not in package.json`);
                  this.score -= 5;
                }
              }
            }

            async detectVersionConflicts() {
              if (!this.lockfileJson?.packages) return;

              console.log('âš ï¸ Detecting version conflicts...');

              const packages = this.lockfileJson.packages;
              const packageVersions = {};

              // Collect all package versions
              for (const [path, pkg] of Object.entries(packages)) {
                if (path === '') continue; // Skip root

                const name = pkg.name || path.split('/').pop();
                if (!packageVersions[name]) {
                  packageVersions[name] = [];
                }
                packageVersions[name].push(pkg.version);
              }

              // Detect conflicts
              for (const [name, versions] of Object.entries(packageVersions)) {
                const uniqueVersions = [...new Set(versions)];
                if (uniqueVersions.length > 1) {
                  this.addWarning('version_conflict', `Multiple versions of ${name}: ${uniqueVersions.join(', ')}`);
                  this.score -= 3;
                }
              }
            }

            async scanSecurityVulnerabilities() {
              console.log('ðŸ”’ Scanning for security vulnerabilities...');

              // This would integrate with npm audit or similar tools
              // For now, we'll do basic checks

              if (this.packageJson?.dependencies) {
                const suspiciousPatterns = [
                  'event-stream', 'eslint-scope', 'getcookies', 'http-server-legacy'
                ];

                for (const dep of Object.keys(this.packageJson.dependencies)) {
                  if (suspiciousPatterns.some(pattern => dep.includes(pattern))) {
                    this.addWarning('suspicious_dependency', `Potentially suspicious dependency: ${dep}`);
                    this.score -= 5;
                  }
                }
              }
            }

            async analyzeSizeAndGrowth() {
              console.log('ðŸ“ Analyzing size and growth patterns...');

              const lockfileSize = fs.statSync('package-lock.json').size;
              const packageCount = this.lockfileJson?.packages ? Object.keys(this.lockfileJson.packages).length : 0;

              // Size thresholds
              if (lockfileSize > 10 * 1024 * 1024) { // 10MB
                this.addWarning('large_lockfile', `Large lockfile size: ${Math.round(lockfileSize / 1024 / 1024)}MB`);
                this.score -= 10;
              }

              // Package count thresholds
              if (packageCount > 2000) {
                this.addWarning('high_package_count', `High package count: ${packageCount}`);
                this.score -= 5;
              }

              this.metrics = {
                lockfileSize,
                packageCount,
                sizePerPackage: packageCount > 0 ? lockfileSize / packageCount : 0
              };
            }

            async verifyPackageIntegrity() {
              console.log('ðŸ›¡ï¸ Verifying package integrity...');

              if (!this.lockfileJson?.packages) return;

              let integrityChecks = 0;
              let integrityFailures = 0;

              for (const [path, pkg] of Object.entries(this.lockfileJson.packages)) {
                if (path === '' || !pkg.integrity) continue;

                integrityChecks++;

                // Basic integrity format validation
                if (!pkg.integrity.match(/^(sha\d+|md5|sha1)-/)) {
                  integrityFailures++;
                  this.addIssue('medium', 'invalid_integrity', `Invalid integrity hash for ${pkg.name || path}`);
                }
              }

              if (integrityFailures > 0) {
                const failureRate = integrityFailures / integrityChecks;
                this.score -= Math.round(failureRate * 20);

                if (failureRate > 0.1) {
                  this.addIssue('high', 'high_integrity_failure_rate', `${Math.round(failureRate * 100)}% integrity failures`);
                }
              }
            }

            async assessPredictiveRisk() {
              console.log('ðŸ”® Assessing predictive risk factors...');

              const riskFactors = [];

              // Risk factor: High churn dependencies
              if (this.packageJson?.dependencies) {
                const highChurnPackages = ['lodash', 'moment', 'request', 'bower'];
                for (const pkg of highChurnPackages) {
                  if (this.packageJson.dependencies[pkg]) {
                    riskFactors.push(`High-churn dependency: ${pkg}`);
                  }
                }
              }

              // Risk factor: Large dependency tree
              if (this.metrics?.packageCount > 1000) {
                riskFactors.push('Large dependency tree increases corruption risk');
              }

              // Risk factor: Old lockfile version
              if (this.lockfileJson?.lockfileVersion < 2) {
                riskFactors.push('Old lockfile version has known issues');
              }

              this.riskFactors = riskFactors;
              if (riskFactors.length > 0) {
                this.score -= riskFactors.length * 2;
              }
            }

            addIssue(severity, type, message) {
              this.issues.push({ severity, type, message, timestamp: new Date().toISOString() });
            }

            addWarning(type, message) {
              this.warnings.push({ type, message, timestamp: new Date().toISOString() });
            }

            generateReport() {
              const riskLevel = this.score >= 85 ? 'low' : this.score >= 60 ? 'medium' : 'high';
              const alertLevel = this.issues.some(i => i.severity === 'critical') ? 'critical' :
                               this.issues.some(i => i.severity === 'high') ? 'high' :
                               this.issues.some(i => i.severity === 'medium') ? 'medium' : 'none';

              return {
                timestamp: new Date().toISOString(),
                integrity_score: this.score,
                risk_level: riskLevel,
                alert_level: alertLevel,
                issues_found: this.issues.length > 0,
                requires_action: alertLevel !== 'none',
                metrics: this.metrics || {},
                issues: this.issues,
                warnings: this.warnings,
                risk_factors: this.riskFactors || [],
                recommendations: this.generateRecommendations()
              };
            }

            generateRecommendations() {
              const recommendations = [];

              if (this.score < 70) {
                recommendations.push('Consider running emergency lockfile repair');
              }

              if (this.issues.some(i => i.type === 'version_conflict')) {
                recommendations.push('Resolve version conflicts with npm dedupe');
              }

              if (this.warnings.some(w => w.type === 'large_lockfile')) {
                recommendations.push('Consider dependency cleanup to reduce lockfile size');
              }

              if (this.riskFactors.length > 2) {
                recommendations.push('High risk factors detected - consider proactive maintenance');
              }

              return recommendations;
            }
          }

          // Run analysis
          const analyzer = new LockfileIntegrityAnalyzer();
          analyzer.analyze().then(report => {
            console.log(JSON.stringify(report, null, 2));

            // Save report first
            require('fs').writeFileSync(process.env.report_file || 'integrity-report.json', JSON.stringify(report, null, 2));

            // Write outputs to file for shell processing
            require('fs').writeFileSync('analysis-outputs.txt', [
              `integrity_score=${report.integrity_score}`,
              `risk_level=${report.risk_level}`,
              `issues_found=${report.issues_found}`,
              `requires_action=${report.requires_action}`,
              `alert_level=${report.alert_level}`,
              `report_file=${process.env.report_file || 'integrity-report.json'}`
            ].join('\n'));

          }).catch(error => {
            console.error('Analysis failed:', error);
            process.exit(1);
          });
          EOF

          # Execute analysis
          export report_file="$report_file"
          node integrity_analysis.js

          # Read outputs from file and set GitHub Actions outputs
          if [[ -f "analysis-outputs.txt" ]]; then
            cat analysis-outputs.txt >> $GITHUB_OUTPUT
          else
            echo "integrity_score=0" >> $GITHUB_OUTPUT
            echo "risk_level=critical" >> $GITHUB_OUTPUT
            echo "issues_found=true" >> $GITHUB_OUTPUT
            echo "requires_action=true" >> $GITHUB_OUTPUT
            echo "alert_level=critical" >> $GITHUB_OUTPUT
          fi

      - name: ðŸ“Š Historical Trend Analysis
        id: trend-analysis
        run: |
          echo "ðŸ“Š Analyzing historical integrity trends..."

          # Initialize trend data
          echo "trend_direction=stable" >> $GITHUB_OUTPUT
          echo "trend_confidence=low" >> $GITHUB_OUTPUT
          echo "degradation_detected=false" >> $GITHUB_OUTPUT

          # Check for previous reports
          if [[ -d ".github/integrity-reports" ]]; then
            report_count=$(find .github/integrity-reports -name "*.json" | wc -l)
            echo "ðŸ“ˆ Found $report_count historical reports"

            if [[ $report_count -ge 2 ]]; then
              # Analyze trend from last 5 reports
              recent_reports=$(find .github/integrity-reports -name "*.json" | sort | tail -5)

              echo "ðŸ” Analyzing trends from recent reports..."

              # Simple trend analysis
              scores=()
              for report in $recent_reports; do
                if [[ -f "$report" ]]; then
                  score=$(grep -o '"integrity_score":[0-9]*' "$report" | cut -d':' -f2 || echo "100")
                  scores+=($score)
                fi
              done

              if [[ ${#scores[@]} -ge 2 ]]; then
                first_score=${scores[0]}
                last_score=${scores[-1]}

                if [[ $last_score -lt $((first_score - 10)) ]]; then
                  echo "trend_direction=declining" >> $GITHUB_OUTPUT
                  echo "degradation_detected=true" >> $GITHUB_OUTPUT
                  echo "âš ï¸ Declining trend detected"
                elif [[ $last_score -gt $((first_score + 10)) ]]; then
                  echo "trend_direction=improving" >> $GITHUB_OUTPUT
                  echo "âœ… Improving trend detected"
                fi

                echo "trend_confidence=high" >> $GITHUB_OUTPUT
              fi
            fi
          else
            mkdir -p .github/integrity-reports
            echo "ðŸ“ Created integrity reports directory"
          fi

      - name: ðŸŽ¯ Risk Scoring and Alerting
        id: risk-scoring
        run: |
          echo "ðŸŽ¯ Calculating comprehensive risk score..."

          # Get current analysis results
          integrity_score="${{ steps.integrity-analysis.outputs.integrity_score }}"
          risk_level="${{ steps.integrity-analysis.outputs.risk_level }}"
          alert_level="${{ steps.integrity-analysis.outputs.alert_level }}"
          issues_found="${{ steps.integrity-analysis.outputs.issues_found }}"
          degradation_detected="${{ steps.trend-analysis.outputs.degradation_detected }}"

          # Calculate composite risk score
          risk_score=0

          # Factor in integrity score
          if [[ $integrity_score -lt 50 ]]; then
            risk_score=$((risk_score + 40))
          elif [[ $integrity_score -lt 70 ]]; then
            risk_score=$((risk_score + 25))
          elif [[ $integrity_score -lt 85 ]]; then
            risk_score=$((risk_score + 10))
          fi

          # Factor in trend analysis
          if [[ "$degradation_detected" == "true" ]]; then
            risk_score=$((risk_score + 20))
          fi

          # Factor in issues
          if [[ "$issues_found" == "true" ]]; then
            case "$alert_level" in
              "critical") risk_score=$((risk_score + 30)) ;;
              "high") risk_score=$((risk_score + 20)) ;;
              "medium") risk_score=$((risk_score + 10)) ;;
            esac
          fi

          # Determine final risk assessment
          if [[ $risk_score -ge 60 ]]; then
            final_risk="critical"
            action_required="immediate"
          elif [[ $risk_score -ge 40 ]]; then
            final_risk="high"
            action_required="soon"
          elif [[ $risk_score -ge 20 ]]; then
            final_risk="medium"
            action_required="scheduled"
          else
            final_risk="low"
            action_required="none"
          fi

          echo "risk_score=$risk_score" >> $GITHUB_OUTPUT
          echo "final_risk=$final_risk" >> $GITHUB_OUTPUT
          echo "action_required=$action_required" >> $GITHUB_OUTPUT

          echo "ðŸŽ¯ Risk Assessment Complete:"
          echo "   Risk Score: $risk_score/100"
          echo "   Risk Level: $final_risk"
          echo "   Action Required: $action_required"

      - name: ðŸš¨ Generate Early Warning Alerts
        id: early-warning
        if: steps.risk-scoring.outputs.action_required != 'none'
        run: |
          echo "ðŸš¨ Generating early warning alerts..."

          action_required="${{ steps.risk-scoring.outputs.action_required }}"
          final_risk="${{ steps.risk-scoring.outputs.final_risk }}"
          integrity_score="${{ steps.integrity-analysis.outputs.integrity_score }}"

          # Generate alert message
          cat > alert_message.md << EOF
          # ðŸš¨ Lockfile Integrity Alert

          **Risk Level**: $final_risk
          **Integrity Score**: $integrity_score/100
          **Action Required**: $action_required

          ## ðŸ“Š Analysis Summary

          **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
          **Repository**: ${{ github.repository }}
          **Branch**: ${{ github.ref_name }}
          **Commit**: ${{ github.sha }}

          ## ðŸ“‹ Issues Detected

          EOF

          # Add issues from report if available
          if [[ -f "${{ steps.integrity-analysis.outputs.report_file }}" ]]; then
            echo "Reading issues from report file..."
            # This would parse and add specific issues
            echo "**Detailed analysis available in workflow logs**" >> alert_message.md
          fi

          cat >> alert_message.md << EOF

          ## ðŸ”® Predictive Assessment

          $([ "${{ steps.trend-analysis.outputs.degradation_detected }}" == "true" ] && echo "âš ï¸ **Degradation Trend Detected** - Integrity scores declining over time" || echo "âœ… No degradation trend detected")

          ## ðŸ’¡ Recommended Actions

          EOF

          case "$action_required" in
            "immediate")
              cat >> alert_message.md << EOF
          - [ ] **IMMEDIATE**: Review lockfile integrity issues
          - [ ] **IMMEDIATE**: Consider running emergency repair workflow
          - [ ] **IMMEDIATE**: Check for dependency conflicts
          - [ ] **24 HOURS**: Implement preventive measures
          EOF
              ;;
            "soon")
              cat >> alert_message.md << EOF
          - [ ] **48 HOURS**: Review and address integrity warnings
          - [ ] **1 WEEK**: Optimize dependency management
          - [ ] **1 WEEK**: Update monitoring thresholds
          EOF
              ;;
            "scheduled")
              cat >> alert_message.md << EOF
          - [ ] **2 WEEKS**: Schedule maintenance review
          - [ ] **1 MONTH**: Dependency cleanup and optimization
          EOF
              ;;
          esac

          cat >> alert_message.md << EOF

          ## ðŸ”— Resources

          - [Emergency Repair Workflow](https://github.com/${{ github.repository }}/actions/workflows/emergency-lockfile-repair.yml)
          - [Backup Manager Documentation](https://github.com/${{ github.repository }}/blob/main/docs/features/emergency-lockfile-repair.md)
          - [Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ---
          *Generated by Lockfile Integrity Monitoring*
          EOF

          echo "alert_generated=true" >> $GITHUB_OUTPUT

      - name: ðŸ“¢ Create Early Warning Issue
        if: steps.early-warning.outputs.alert_generated == 'true' && steps.risk-scoring.outputs.final_risk == 'critical'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const alertContent = fs.readFileSync('alert_message.md', 'utf8');

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ðŸš¨ Critical Lockfile Integrity Alert - Score: ${{ steps.integrity-analysis.outputs.integrity_score }}/100`,
              body: alertContent,
              labels: ['lockfile', 'integrity', 'critical', 'early-warning']
            });

      - name: ðŸ“ˆ Update Metrics Dashboard
        if: always()
        run: |
          echo "ðŸ“ˆ Updating integrity metrics dashboard..."

          # Create or update metrics file
          metrics_dir=".github/metrics"
          metrics_file="$metrics_dir/lockfile-integrity-metrics.json"
          mkdir -p "$metrics_dir"

          # Current metrics
          cat > current_metrics.json << EOF
          {
            "timestamp": "$(date -u '+%Y-%m-%dT%H:%M:%S.%3NZ')",
            "workflow_run": "${{ github.run_id }}",
            "trigger_event": "${{ github.event_name }}",
            "branch": "${{ github.ref_name }}",
            "commit_sha": "${{ github.sha }}",
            "integrity_analysis": {
              "score": ${{ steps.integrity-analysis.outputs.integrity_score || 0 }},
              "risk_level": "${{ steps.integrity-analysis.outputs.risk_level || 'unknown' }}",
              "alert_level": "${{ steps.integrity-analysis.outputs.alert_level || 'none' }}",
              "issues_found": ${{ steps.integrity-analysis.outputs.issues_found || false }},
              "requires_action": ${{ steps.integrity-analysis.outputs.requires_action || false }}
            },
            "trend_analysis": {
              "direction": "${{ steps.trend-analysis.outputs.trend_direction || 'unknown' }}",
              "confidence": "${{ steps.trend-analysis.outputs.trend_confidence || 'low' }}",
              "degradation_detected": ${{ steps.trend-analysis.outputs.degradation_detected || false }}
            },
            "risk_assessment": {
              "risk_score": ${{ steps.risk-scoring.outputs.risk_score || 0 }},
              "final_risk": "${{ steps.risk-scoring.outputs.final_risk || 'unknown' }}",
              "action_required": "${{ steps.risk-scoring.outputs.action_required || 'none' }}"
            }
          }
          EOF

          # Merge with existing metrics (keep last 100 entries)
          if [[ -f "$metrics_file" ]]; then
            # Simple append for now - in production would use proper JSON merging
            cp current_metrics.json "${metrics_file}.new"
            mv "${metrics_file}.new" "$metrics_file"
          else
            cp current_metrics.json "$metrics_file"
          fi

          echo "âœ… Metrics updated"

      - name: ðŸ“Š Final Status Report
        if: always()
        run: |
          echo "ðŸ“Š LOCKFILE INTEGRITY MONITORING FINAL REPORT"
          echo "=============================================="
          echo "ðŸŽ¯ **Integrity Score**: ${{ steps.integrity-analysis.outputs.integrity_score || 'N/A' }}/100"
          echo "ðŸ“Š **Risk Level**: ${{ steps.integrity-analysis.outputs.risk_level || 'unknown' }}"
          echo "ðŸš¨ **Alert Level**: ${{ steps.integrity-analysis.outputs.alert_level || 'none' }}"
          echo "âš ï¸ **Issues Found**: ${{ steps.integrity-analysis.outputs.issues_found || 'false' }}"
          echo "ðŸ”® **Trend**: ${{ steps.trend-analysis.outputs.trend_direction || 'unknown' }}"
          echo "ðŸŽ¯ **Final Risk**: ${{ steps.risk-scoring.outputs.final_risk || 'unknown' }}"
          echo "âš¡ **Action Required**: ${{ steps.risk-scoring.outputs.action_required || 'none' }}"
          echo "â° **Completed**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"

          # Set workflow status
          if [[ "${{ steps.risk-scoring.outputs.final_risk }}" == "critical" ]]; then
            echo "::error title=Critical Risk Detected::Lockfile integrity monitoring detected critical issues requiring immediate attention"
          elif [[ "${{ steps.risk-scoring.outputs.final_risk }}" == "high" ]]; then
            echo "::warning title=High Risk Detected::Lockfile integrity monitoring detected high-risk conditions"
          elif [[ "${{ steps.risk-scoring.outputs.final_risk }}" == "medium" ]]; then
            echo "::notice title=Medium Risk Detected::Lockfile integrity monitoring detected medium-risk conditions"
          else
            echo "::notice title=Integrity Check Passed::Lockfile integrity monitoring completed successfully"
          fi